{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baron2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mrrobi/Capstone-Project/blob/main/baron2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2QiqqbSMieK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9cf1f3-3eac-467d-deaa-99444f2e356b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLfzAEkXMncV"
      },
      "source": [
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pylab as pl\n",
        "from scipy import interp\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPbPETtnMqET"
      },
      "source": [
        "s1 = pd.read_csv(\"/content/drive/My Drive/capstone/Dataset/baron/human2.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aIeghUVMvFX"
      },
      "source": [
        "co=[]\n",
        "s1=np.asarray(s1)\n",
        "for x in range (len(s1)):\n",
        "  co.append(str(s1[x][2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yU_RVQbQK6M"
      },
      "source": [
        "#from collections import Counter\n",
        "#Counter(co)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQavwbT7Mv98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1980ce7-6dbb-401b-829d-ecdf7efce9c4"
      },
      "source": [
        "items=[]\n",
        "for x in range (len(s1)):\n",
        "  if(s1[x][2] not in items):\n",
        "    items.append(str(s1[x][2]))\n",
        "for x in items[:]:\n",
        "  z=co.count(x)\n",
        "  print(z)\n",
        "  if z<84:\n",
        "    items.remove(x)\n",
        "\n",
        " \n",
        "print(items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125\n",
            "676\n",
            "81\n",
            "301\n",
            "371\n",
            "17\n",
            "22\n",
            "86\n",
            "23\n",
            "2\n",
            "6\n",
            "9\n",
            "3\n",
            "2\n",
            "['delta', 'alpha', 'ductal', 'beta', 'gamma']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qemiEHC-vYlk"
      },
      "source": [
        "x=0\n",
        "for x in range (len(s1)-1,0,-1):\n",
        "  if s1[x][2] not in items:\n",
        "    s1 = np.delete(s1, x, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PHPOHm1HEh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd0a3e7-f4d8-48e2-f626-31e9b06268a9"
      },
      "source": [
        "co=[]\n",
        "for x in range (len(s1)):\n",
        "  co.append(str(s1[x][2]))\n",
        "for x in range (len(co)):\n",
        "  if(co[x] in items):\n",
        "    co[x]=items.index(co[x])\n",
        "  else:\n",
        "    items.append(co[x])\n",
        "    co[x]=items.index(co[x])\n",
        "\n",
        "print(co)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 1, 3, 2, 1, 1, 2, 1, 1, 0, 2, 1, 0, 2, 2, 2, 2, 1, 0, 0, 0, 1, 2, 1, 1, 0, 2, 0, 1, 1, 1, 1, 2, 2, 1, 3, 1, 3, 3, 3, 1, 0, 0, 1, 3, 1, 1, 1, 2, 3, 2, 2, 1, 3, 2, 1, 3, 1, 2, 1, 3, 1, 2, 2, 1, 1, 2, 1, 1, 1, 3, 1, 3, 1, 2, 0, 4, 1, 2, 1, 3, 3, 4, 1, 0, 3, 1, 3, 1, 1, 1, 3, 2, 2, 1, 3, 1, 2, 1, 3, 1, 2, 1, 0, 3, 2, 3, 1, 3, 2, 1, 1, 1, 1, 2, 1, 2, 3, 2, 3, 1, 3, 1, 1, 3, 1, 1, 1, 1, 3, 2, 1, 1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 2, 3, 3, 1, 4, 2, 3, 4, 2, 1, 2, 0, 2, 3, 3, 3, 1, 0, 3, 1, 3, 2, 3, 4, 1, 1, 1, 0, 1, 2, 1, 3, 1, 3, 1, 1, 1, 3, 3, 1, 4, 3, 1, 1, 1, 3, 2, 3, 1, 3, 3, 4, 1, 1, 1, 3, 1, 1, 0, 4, 3, 1, 2, 3, 4, 3, 3, 2, 2, 1, 3, 3, 2, 3, 2, 1, 1, 0, 1, 3, 1, 0, 3, 3, 0, 2, 1, 0, 1, 3, 2, 3, 2, 3, 1, 3, 1, 3, 3, 1, 3, 1, 4, 3, 2, 3, 1, 1, 1, 1, 2, 3, 1, 1, 2, 1, 2, 1, 1, 4, 2, 2, 1, 1, 2, 3, 2, 1, 2, 1, 2, 3, 3, 3, 2, 2, 1, 0, 1, 3, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 3, 0, 1, 1, 2, 1, 1, 4, 2, 1, 0, 3, 1, 3, 1, 1, 1, 4, 2, 1, 1, 4, 1, 3, 2, 2, 3, 1, 1, 1, 1, 1, 3, 1, 3, 2, 4, 3, 2, 2, 1, 4, 1, 0, 1, 2, 1, 3, 4, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 2, 1, 1, 1, 3, 2, 4, 0, 2, 0, 3, 1, 2, 4, 1, 1, 1, 4, 1, 2, 1, 1, 3, 2, 1, 4, 0, 1, 1, 2, 1, 1, 1, 4, 1, 3, 1, 1, 3, 2, 0, 4, 1, 2, 3, 3, 1, 4, 4, 2, 1, 3, 3, 1, 3, 3, 1, 2, 1, 1, 1, 4, 1, 3, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 3, 3, 3, 2, 1, 1, 2, 1, 3, 2, 1, 3, 1, 1, 3, 4, 3, 2, 2, 2, 2, 1, 3, 2, 3, 3, 3, 4, 2, 2, 3, 2, 1, 1, 2, 1, 2, 3, 1, 2, 3, 0, 1, 1, 1, 1, 0, 2, 1, 0, 0, 0, 3, 0, 2, 2, 2, 2, 1, 0, 3, 0, 2, 3, 0, 1, 1, 2, 3, 2, 1, 0, 2, 2, 3, 1, 1, 3, 1, 3, 2, 2, 2, 3, 0, 3, 3, 2, 1, 2, 2, 3, 1, 3, 3, 3, 1, 1, 3, 3, 1, 3, 3, 3, 2, 3, 3, 2, 3, 3, 1, 2, 2, 3, 2, 1, 2, 4, 1, 3, 3, 3, 3, 1, 3, 4, 3, 1, 2, 3, 1, 1, 3, 1, 1, 1, 1, 1, 3, 4, 1, 3, 0, 2, 1, 3, 1, 1, 1, 3, 3, 2, 3, 3, 1, 3, 3, 2, 1, 0, 3, 3, 1, 3, 1, 3, 2, 3, 1, 1, 0, 3, 3, 1, 2, 3, 1, 0, 0, 1, 2, 0, 1, 2, 2, 1, 3, 2, 2, 1, 1, 0, 0, 1, 1, 2, 1, 1, 0, 1, 3, 3, 1, 2, 0, 1, 0, 3, 4, 0, 4, 3, 2, 1, 2, 1, 2, 3, 2, 1, 3, 3, 2, 3, 1, 2, 1, 3, 3, 2, 1, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 2, 3, 2, 1, 3, 1, 1, 2, 1, 1, 3, 3, 3, 3, 2, 1, 2, 1, 3, 3, 2, 3, 0, 1, 1, 3, 2, 3, 1, 3, 1, 3, 3, 3, 3, 1, 1, 3, 1, 0, 1, 3, 3, 3, 1, 1, 1, 3, 1, 3, 2, 2, 4, 3, 1, 2, 3, 2, 2, 1, 0, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 4, 1, 1, 4, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 2, 0, 1, 1, 1, 1, 3, 3, 1, 1, 3, 1, 3, 3, 1, 1, 3, 1, 3, 0, 3, 1, 3, 4, 1, 1, 1, 3, 3, 3, 1, 1, 4, 1, 1, 1, 1, 3, 3, 1, 2, 2, 1, 1, 2, 3, 1, 1, 2, 3, 1, 1, 1, 2, 1, 4, 1, 1, 2, 2, 2, 1, 4, 2, 1, 2, 3, 2, 1, 1, 3, 3, 3, 1, 1, 2, 1, 1, 1, 1, 4, 3, 2, 3, 1, 3, 1, 1, 3, 1, 1, 4, 2, 3, 1, 1, 1, 1, 4, 0, 1, 3, 3, 1, 4, 3, 1, 1, 2, 3, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 3, 1, 1, 1, 3, 3, 1, 1, 2, 1, 3, 1, 3, 2, 3, 1, 1, 4, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 3, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 2, 1, 1, 1, 1, 3, 3, 3, 2, 3, 1, 3, 2, 1, 1, 1, 3, 4, 3, 2, 2, 1, 4, 4, 1, 2, 4, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 3, 1, 1, 4, 4, 2, 1, 1, 2, 0, 1, 1, 3, 1, 2, 1, 2, 1, 3, 3, 1, 1, 2, 3, 3, 1, 4, 2, 1, 3, 4, 3, 3, 3, 3, 3, 3, 1, 3, 1, 2, 3, 1, 2, 1, 3, 0, 0, 3, 2, 1, 3, 2, 1, 0, 2, 1, 2, 0, 2, 1, 2, 2, 0, 0, 1, 3, 0, 0, 3, 0, 2, 2, 2, 2, 0, 1, 0, 1, 3, 2, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 3, 3, 1, 1, 3, 0, 1, 1, 2, 1, 3, 1, 1, 2, 1, 1, 3, 0, 1, 1, 1, 1, 1, 1, 2, 3, 2, 2, 1, 1, 1, 1, 2, 0, 0, 3, 1, 2, 2, 3, 1, 0, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 2, 2, 1, 2, 2, 1, 1, 2, 3, 3, 1, 0, 2, 3, 1, 1, 1, 1, 3, 3, 3, 1, 3, 0, 1, 1, 1, 3, 1, 1, 2, 3, 1, 2, 0, 1, 3, 1, 1, 1, 2, 1, 2, 0, 3, 0, 2, 1, 1, 3, 2, 2, 2, 2, 1, 0, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 2, 1, 1, 3, 2, 3, 2, 1, 3, 1, 0, 1, 2, 1, 1, 1, 2, 0, 3, 1, 1, 1, 3, 1, 2, 1, 1, 3, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 2, 3, 3, 1, 2, 2, 4, 1, 1, 0, 3, 1, 3, 3, 0, 0, 0, 3, 2, 1, 3, 3, 1, 1, 0, 3, 1, 4, 1, 3, 1, 2, 2, 3, 3, 2, 3, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 0, 3, 3, 3, 1, 1, 1, 2, 2, 1, 3, 3, 1, 3, 1, 0, 3, 2, 1, 0, 2, 3, 0, 2, 1, 0, 2, 3, 3, 1, 3, 2, 3, 1, 1, 2, 2, 1, 4, 0, 2, 1, 3, 2, 1, 1, 4, 1, 1, 2, 4, 1, 1, 1, 0, 4, 1, 0, 1, 2, 4, 3, 2, 4, 1, 3, 4, 1, 4, 1, 1, 3, 2, 1, 2, 0, 2, 1, 1, 3, 1, 3, 1, 2, 4, 1, 1, 1, 2, 1, 4, 3, 2, 1, 1, 1, 2, 1, 3, 2, 1, 3, 1, 4, 4, 1, 3, 1, 1, 3, 1, 1, 4, 1, 0, 1, 1, 3, 3, 1, 1, 2, 4, 1, 2, 4, 0, 4, 1, 2, 3, 3, 4, 3, 1, 2, 3, 3, 0, 4, 2, 1, 1, 0, 1, 2, 3, 3, 2, 1, 2, 3, 1, 1, 1, 4, 1, 0, 1, 3, 2, 1, 1, 3, 1, 3, 3, 2, 2, 1, 4, 1, 1, 2, 2, 3, 1, 4, 2, 3, 2, 3, 1, 1, 3, 1, 1, 2, 1, 2, 0, 1, 4, 3, 1, 1, 1, 3, 1, 1, 2, 2, 2, 3, 2, 3, 2, 1, 1, 3, 4, 1, 1, 3, 1, 3, 3, 3, 4, 4, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 3, 3, 1, 1, 2, 3, 1, 2, 4, 3, 3, 1, 3, 1, 4, 3, 2, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqCQ6opfM9oI"
      },
      "source": [
        "df = pd.DataFrame(data=s1)\n",
        "x= np.asarray(df.iloc[:,3:])\n",
        "y=np.asarray(co)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AW2Z2-GRWtZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5573416e-866a-4101-f25b-0fda6c6a5cb9"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 3 0 ... 0 2 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "038vKWOONGBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97495c4d-4c33-4662-88bd-7ed920ff5993"
      },
      "source": [
        "import keras\n",
        "from sklearn.utils.multiclass import type_of_target\n",
        "print(type_of_target(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "multiclass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmcI8rOyNIj0"
      },
      "source": [
        "seed = 40\n",
        "np.random.seed(seed)\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuxM_wdaNK-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efae8860-2ac1-491d-b1e0-7cba155daeaa"
      },
      "source": [
        "#Random Forest\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "# acc_train = []\n",
        "# recall_train = []\n",
        "# pre_train = []\n",
        "# balance_train = []\n",
        "\n",
        "acc_test = []\n",
        "recall_test = []\n",
        "auROC_test = []\n",
        "pre_test = []\n",
        "balance_test = []\n",
        "mean_tpr = 0.0\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "all_tpr = []\n",
        "i = 0\n",
        "for train_index, test_index in kf.split(x,y):\n",
        "\n",
        "  x_train, x_test = x[train_index], x[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  \n",
        "  probas_ = clf.fit(x_train, y_train).predict_proba(x_test)\n",
        "\n",
        "  y_test_pred = clf.predict(x_test)\n",
        "\n",
        "  acc_test.append(accuracy_score(y_test, y_test_pred))\n",
        "  recall_test.append(recall_score(y_test, y_test_pred, average='macro'))\n",
        "  pre_test.append(precision_score(y_test, y_test_pred, average='micro'))\n",
        "  balance_test.append(balanced_accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "\n",
        "print(\"Test:\")\n",
        "print(\"ACCURACY:{0:3.6}\".format(np.mean(acc_test)*100))\n",
        "print(\"RECALL: {0:3.6}\".format(np.mean(recall_test)*100))\n",
        "print(\"Precision: {0:3.6}\".format(np.mean(pre_test)*100))\n",
        "print(\"Balanced: {0:3.6}\".format(np.mean(balance_test)*100))\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_test_pred))\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# pl.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
        "# #figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "# mean_tpr /= 5\n",
        "# mean_tpr[-1] = 1.0\n",
        "# mean_auc = auc(mean_fpr, mean_tpr)\n",
        "# pl.plot(mean_fpr, mean_tpr, 'k--',\n",
        "#         label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
        "\n",
        "# pl.xlim([-0.05, 1.05])\n",
        "# pl.ylim([-0.05, 1.05])\n",
        "# pl.xlabel('False Positive Rate')\n",
        "# pl.ylabel('True Positive Rate')\n",
        "# pl.title('Receiver operating characteristic example')\n",
        "# pl.legend(loc=\"lower right\")\n",
        "# pl.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test:\n",
            "ACCURACY:97.6905\n",
            "RECALL: 92.0718\n",
            "Precision: 97.6905\n",
            "Balanced: 92.0718\n",
            "[[ 25   0   0   0   0]\n",
            " [  0 135   0   0   0]\n",
            " [  0   0  60   0   0]\n",
            " [  0   0   0  74   0]\n",
            " [  0   9   0   0   8]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.94      1.00      0.97       135\n",
            "           2       1.00      1.00      1.00        60\n",
            "           3       1.00      1.00      1.00        74\n",
            "           4       1.00      0.47      0.64        17\n",
            "\n",
            "    accuracy                           0.97       311\n",
            "   macro avg       0.99      0.89      0.92       311\n",
            "weighted avg       0.97      0.97      0.97       311\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJAqzzy3SmMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "914ad9d3-b2ec-4509-9598-63268271a3ab"
      },
      "source": [
        "#Adaboost \n",
        "\n",
        "clf = AdaBoostClassifier()\n",
        "# acc_train = []\n",
        "# recall_train = []\n",
        "# pre_train = []\n",
        "# balance_train = []\n",
        "\n",
        "acc_test = []\n",
        "recall_test = []\n",
        "auROC_test = []\n",
        "pre_test = []\n",
        "balance_test = []\n",
        "mean_tpr = 0.0\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "all_tpr = []\n",
        "i = 0\n",
        "for train_index, test_index in kf.split(x,y):\n",
        "\n",
        "  x_train, x_test = x[train_index], x[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  \n",
        "  probas_ = clf.fit(x_train, y_train).predict_proba(x_test)\n",
        "  # fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
        "  # mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
        "  # mean_tpr[0] = 0.0\n",
        "  # roc_auc = auc(fpr, tpr)\n",
        "  # pl.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
        "  # i = i + 1\n",
        "\n",
        "  y_test_pred = clf.predict(x_test)\n",
        "\n",
        "  acc_test.append(accuracy_score(y_test, y_test_pred))\n",
        "  recall_test.append(recall_score(y_test, y_test_pred, average='macro'))\n",
        "  pre_test.append(precision_score(y_test, y_test_pred, average='micro'))\n",
        "  balance_test.append(balanced_accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "  # y_train_pred = clf.predict(x_train)\n",
        "\n",
        "  # acc_train.append(accuracy_score(y_train, y_train_pred))\n",
        "  # recall_train.append(recall_score(y_train, y_train_pred))\n",
        "  # pre_train.append(precision_score(y_train, y_train_pred))\n",
        "  # balance_train.append(balanced_accuracy_score(y_train, y_train_pred))\n",
        "\n",
        "\n",
        "\n",
        "# print(\"train:\")\n",
        "# print(\"ACCURACY:{0:3.6}\".format(np.mean(acc_train)*100))\n",
        "# print(\"RECALL: {0:3.6}\".format(np.mean(recall_train)*100))\n",
        "# print(\"Precision: {0:3.6}\".format(np.mean(pre_train)*100))\n",
        "# print(\"Balanced: {0:3.6}\".format(np.mean(balance_train)*100))\n",
        "\n",
        "print(\"Test:\")\n",
        "print(\"ACCURACY:{0:3.6}\".format(np.mean(acc_test)*100))\n",
        "print(\"RECALL: {0:3.6}\".format(np.mean(recall_test)*100))\n",
        "print(\"Precision: {0:3.6}\".format(np.mean(pre_test)*100))\n",
        "print(\"Balanced: {0:3.6}\".format(np.mean(balance_test)*100))\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_test_pred))\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# pl.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
        "# #figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "# mean_tpr /= 5\n",
        "# mean_tpr[-1] = 1.0\n",
        "# mean_auc = auc(mean_fpr, mean_tpr)\n",
        "# pl.plot(mean_fpr, mean_tpr, 'k--',\n",
        "#         label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
        "\n",
        "# pl.xlim([-0.05, 1.05])\n",
        "# pl.ylim([-0.05, 1.05])\n",
        "# pl.xlabel('False Positive Rate')\n",
        "# pl.ylabel('True Positive Rate')\n",
        "# pl.title('Receiver operating characteristic example')\n",
        "# pl.legend(loc=\"lower right\")\n",
        "# pl.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test:\n",
            "ACCURACY:81.9664\n",
            "RECALL: 67.7685\n",
            "Precision: 81.9664\n",
            "Balanced: 67.7685\n",
            "[[ 25   0   0   0   0]\n",
            " [  0 128   7   0   0]\n",
            " [  0   3  57   0   0]\n",
            " [  0   1  73   0   0]\n",
            " [  0   0  17   0   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.97      0.95      0.96       135\n",
            "           2       0.37      0.95      0.53        60\n",
            "           3       0.00      0.00      0.00        74\n",
            "           4       0.00      0.00      0.00        17\n",
            "\n",
            "    accuracy                           0.68       311\n",
            "   macro avg       0.47      0.58      0.50       311\n",
            "weighted avg       0.57      0.68      0.60       311\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOKPdMYFSors"
      },
      "source": [
        "#SVC\n",
        "\n",
        "clf = SVC()\n",
        "# acc_train = []\n",
        "# recall_train = []\n",
        "# pre_train = []\n",
        "# balance_train = []\n",
        "\n",
        "acc_test = []\n",
        "recall_test = []\n",
        "auROC_test = []\n",
        "pre_test = []\n",
        "balance_test = []\n",
        "mean_tpr = 0.0\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "all_tpr = []\n",
        "i = 0\n",
        "for train_index, test_index in kf.split(x,y):\n",
        "\n",
        "  x_train, x_test = x[train_index], x[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  \n",
        "  clf.fit(x_train, y_train)\n",
        "  # fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
        "  # mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
        "  # mean_tpr[0] = 0.0\n",
        "  # roc_auc = auc(fpr, tpr)\n",
        "  # pl.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
        "  # i = i + 1\n",
        "\n",
        "  y_test_pred = clf.predict(x_test)\n",
        "\n",
        "  acc_test.append(accuracy_score(y_test, y_test_pred))\n",
        "  recall_test.append(recall_score(y_test, y_test_pred, average='macro'))\n",
        "  pre_test.append(precision_score(y_test, y_test_pred, average='micro'))\n",
        "  balance_test.append(balanced_accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "  # y_train_pred = clf.predict(x_train)\n",
        "\n",
        "  # acc_train.append(accuracy_score(y_train, y_train_pred))\n",
        "  # recall_train.append(recall_score(y_train, y_train_pred))\n",
        "  # pre_train.append(precision_score(y_train, y_train_pred))\n",
        "  # balance_train.append(balanced_accuracy_score(y_train, y_train_pred))\n",
        "\n",
        "\n",
        "\n",
        "# print(\"train:\")\n",
        "# print(\"ACCURACY:{0:3.6}\".format(np.mean(acc_train)*100))\n",
        "# print(\"RECALL: {0:3.6}\".format(np.mean(recall_train)*100))\n",
        "# print(\"Precision: {0:3.6}\".format(np.mean(pre_train)*100))\n",
        "# print(\"Balanced: {0:3.6}\".format(np.mean(balance_train)*100))\n",
        "\n",
        "print(\"Test:\")\n",
        "print(\"ACCURACY:{0:3.6}\".format(np.mean(acc_test)*100))\n",
        "print(\"RECALL: {0:3.6}\".format(np.mean(recall_test)*100))\n",
        "print(\"Precision: {0:3.6}\".format(np.mean(pre_test)*100))\n",
        "print(\"Balanced: {0:3.6}\".format(np.mean(balance_test)*100))\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_test_pred))\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "\n",
        "    print(title)\n",
        "    print(disp.confusion_matrix)\n",
        "\n",
        "# pl.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
        "# #figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "# mean_tpr /= 5\n",
        "# mean_tpr[-1] = 1.0\n",
        "# mean_auc = auc(mean_fpr, mean_tpr)\n",
        "# pl.plot(mean_fpr, mean_tpr, 'k--',\n",
        "#         label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
        "\n",
        "# pl.xlim([-0.05, 1.05])\n",
        "# pl.ylim([-0.05, 1.05])\n",
        "# pl.xlabel('False Positive Rate')\n",
        "# pl.ylabel('True Positive Rate')\n",
        "# pl.title('Receiver operating characteristic example')\n",
        "# pl.legend(loc=\"lower right\")\n",
        "# pl.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}